{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some common libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import os, json, cv2, random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import pycocotools\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "\n",
    "def build_kitti_mots_dicts(dataset_path, instances_ids=None):\n",
    "    # Check that the dataset path exists and is a directory.\n",
    "    assert os.path.isdir(dataset_path), f\"Dataset path '{dataset_path}' is not a directory or does not exist.\"\n",
    "\n",
    "    ann_dir = os.path.join(dataset_path, \"instances_txt\")\n",
    "    images_folder = os.path.join(dataset_path, \"training\", \"image_02\")\n",
    "\n",
    "    # Check that the annotation directory exists.\n",
    "    assert os.path.isdir(ann_dir), f\"Annotation directory '{ann_dir}' does not exist or is not a directory.\"\n",
    "    # Check that the images folder exists.\n",
    "    assert os.path.isdir(images_folder), f\"Images folder '{images_folder}' does not exist or is not a directory.\"\n",
    "\n",
    "    dataset_dicts = []\n",
    "    # KITTI-MOTS: 1 -> car, 2 -> pedestrian\n",
    "    # COCO: 0 -> person, 1 -> bicycle, 2 -> car\n",
    "    category_map = {1: 2, 2: 0}\n",
    "\n",
    "    # Iterate over each instance directory in the images folder.\n",
    "    for instance_dir in sorted(os.listdir(images_folder)):\n",
    "        instance_dir_path = os.path.join(images_folder, instance_dir)\n",
    "        if not os.path.isdir(instance_dir_path):\n",
    "            continue  # Skip non-directory entries\n",
    "\n",
    "        try:\n",
    "            instance_number = int(instance_dir)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        if instances_ids and instance_number not in instances_ids:\n",
    "            continue\n",
    "\n",
    "        instance_path = instance_dir_path\n",
    "        ann_file = os.path.join(ann_dir, f\"{instance_number:04d}.txt\")\n",
    "        \n",
    "        annotations = defaultdict(list)\n",
    "        if os.path.exists(ann_file):\n",
    "            # Make sure ann_file is a file.\n",
    "            assert os.path.isfile(ann_file), f\"Annotation file '{ann_file}' exists but is not a file.\"\n",
    "            with open(ann_file, \"r\") as file:\n",
    "                for line in file:\n",
    "                    parts = line.strip().split(\" \")\n",
    "                    # Validate that the annotation line has at least 6 parts.\n",
    "                    if len(parts) < 6:\n",
    "                        raise ValueError(f\"Annotation line has less than 6 parts: {line}\")\n",
    "                    try:\n",
    "                        time_frame = int(parts[0])\n",
    "                        class_id = int(parts[2])\n",
    "                        img_height = int(parts[3])\n",
    "                        img_width = int(parts[4])\n",
    "                    except ValueError:\n",
    "                        raise ValueError(f\"Annotation line contains non-integer values where expected: {line}\")\n",
    "\n",
    "                    # Validate that image dimensions are positive.\n",
    "                    assert img_height > 0 and img_width > 0, f\"Invalid image dimensions in annotation: {img_height}x{img_width}\"\n",
    "\n",
    "                    rle = parts[5].strip()\n",
    "                    # Validate that RLE string is not empty.\n",
    "                    assert rle, f\"Empty RLE in annotation line: {line}\"\n",
    "\n",
    "                    # If the class id is 10, skip this annotation.\n",
    "                    if class_id == 10:\n",
    "                        continue\n",
    "\n",
    "                    # Ensure that the class_id is in the category_map.\n",
    "                    assert class_id in category_map, f\"Class ID {class_id} is not in the category_map {category_map}\"\n",
    "\n",
    "                    mask = {\"counts\": rle, \"size\": [img_height, img_width]}\n",
    "                    bbox = pycocotools.mask.toBbox(mask).tolist()\n",
    "                    \n",
    "                    \"\"\" IMPLEMENT IF SEGMENTATION IS NEEDED\n",
    "                    # Convert to uint8 image for contour extraction.\n",
    "                    segmentation = pycocotools.mask.decode(mask)\n",
    "                    # Check that the segmentation mask dimensions match the expected image dimensions.\n",
    "                    assert segmentation.shape[0] == img_height and segmentation.shape[1] == img_width, (\n",
    "                        f\"Segmentation shape {segmentation.shape} does not match expected dimensions [{img_height}, {img_width}]\"\n",
    "                    )\n",
    "                    seg_uint8 = segmentation.astype(np.uint8)\n",
    "                    contours, hierarchy = cv2.findContours(seg_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    # Ensure that at least one contour was found.\n",
    "                    assert contours is not None and len(contours) > 0, f\"No contours found in segmentation for annotation line: {line}\"\n",
    "                    polygons = [contour.flatten().tolist() for contour in contours if len(contour) >= 6]\n",
    "                    # Ensure that at least one valid polygon exists.\n",
    "                    assert len(polygons) > 0, f\"No valid polygon (at least 3 points) found in annotation line: {line}\"\n",
    "                    \"\"\"\n",
    "                    polygons = []\n",
    "                    \n",
    "                    # Validate that the bounding box values are non-negative and have positive width/height.\n",
    "                    x, y, w, h = bbox\n",
    "                    assert x >= 0 and y >= 0 and w > 0 and h > 0, f\"Invalid bbox values: {bbox}\"\n",
    "\n",
    "                    # Create a unique image ID\n",
    "                    image_id = int(f\"{instance_number:04d}{time_frame:06d}\")\n",
    "\n",
    "                    annotations[image_id].append({\n",
    "                        \"bbox\": bbox,\n",
    "                        \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "                        \"segmentation\": polygons,\n",
    "                        \"category_id\": category_map[class_id],\n",
    "                    })\n",
    "\n",
    "        # Check that the instance_path exists and is a directory.\n",
    "        assert os.path.isdir(instance_path), f\"Instance path '{instance_path}' is not a directory.\"\n",
    "        image_files = sorted(os.listdir(instance_path))\n",
    "        # Ensure that the instance directory contains image files.\n",
    "        assert len(image_files) > 0, f\"No image files found in instance directory '{instance_path}'.\"\n",
    "        for img_file in image_files:\n",
    "            # Process only valid image files based on extension.\n",
    "            if not img_file.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
    "                continue\n",
    "            try:\n",
    "                time_frame = int(os.path.splitext(img_file)[0])\n",
    "            except ValueError:\n",
    "                raise ValueError(f\"Image filename '{img_file}' does not contain a valid integer time frame.\")\n",
    "            image_id = int(f\"{instance_number:04d}{time_frame:06d}\")\n",
    "            file_path = os.path.join(instance_path, img_file)\n",
    "            # Verify that the image file exists.\n",
    "            assert os.path.isfile(file_path), f\"Image file '{file_path}' does not exist or is not a file.\"\n",
    "            # Open image and check dimensions.\n",
    "            with Image.open(file_path) as img:\n",
    "                width, height = img.size\n",
    "                # Validate that the image dimensions are positive.\n",
    "                assert width > 0 and height > 0, f\"Image '{file_path}' has invalid dimensions: {width}x{height}\"\n",
    "\n",
    "            record = {\n",
    "                \"file_name\": file_path,\n",
    "                \"image_id\": image_id,\n",
    "                \"height\": height,\n",
    "                \"width\": width,\n",
    "                \"annotations\": annotations[image_id],\n",
    "            }\n",
    "            dataset_dicts.append(record)\n",
    "\n",
    "    # Final check: ensure that the dataset is not empty.\n",
    "    assert len(dataset_dicts) > 0, \"No data found in dataset, please check the dataset path and structure.\"\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetCatalog.register(\"kitti_mots\", lambda: build_kitti_mots_dicts(\"/home/mcv/datasets/C5/KITTI-MOTS\"))\n",
    "MetadataCatalog.get(\"kitti_mots\").set(thing_classes=[\"person\", \"bicycle\", \"car\"])\n",
    "\n",
    "dataset_dicts = build_kitti_mots_dicts(\"/home/mcv/datasets/C5/KITTI-MOTS\")\n",
    "kitti_mots_metadata = MetadataCatalog.get(\"kitti_mots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    print(d[\"file_name\"], d)\n",
    "    img = cv2.imread(d[\"file_name\"])[:, :, ::-1]\n",
    "    visualizer = Visualizer(img, metadata=kitti_mots_metadata, scale=0.5)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    plt.figure()\n",
    "    plt.imshow(out.get_image())\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task (c): Run inference with pre-trained Faster R-CNN, DeTR and YOLOv(>8) on KITTI-MOTS dataset ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "class CustomPredictor(DefaultPredictor):\n",
    "    def __call__(self, original_image):\n",
    "        outputs = super().__call__(original_image)\n",
    "        instances = outputs[\"instances\"]\n",
    "        filtered_instances = self.filter_instances(instances)\n",
    "        outputs[\"instances\"] = filtered_instances\n",
    "        return outputs\n",
    "\n",
    "    def filter_instances(self, instances):\n",
    "        \"\"\"Keep only allowed classes: COCO class IDs (0=person, 2=car)\"\"\"\n",
    "        pred_classes = instances.pred_classes.tolist()\n",
    "        keep = [i for i, cls in enumerate(pred_classes) if cls in [0, 2]]\n",
    "        filtered_instances = instances[keep]\n",
    "        return filtered_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n",
    "# Output folder\n",
    "cfg.OUTPUT_DIR = \"/ghome/c5mcv07/C5_G7_MCV/Week_1/faster-rcnn/output/pre_trained_inference\"\n",
    "cfg.MODEL.DEVICE = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference\n",
    "random.seed(42)\n",
    "predictor = CustomPredictor(cfg)\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    file_name = d[\"file_name\"]\n",
    "    image_id = d[\"image_id\"]\n",
    "    img = cv2.imread(file_name)[:, :, ::-1]\n",
    "    outputs = predictor(img)  # Run inference\n",
    "    instances = outputs[\"instances\"]\n",
    "    \n",
    "    # We can use `Visualizer` to draw the predictions on the image.\n",
    "    v = Visualizer(img, kitti_mots_metadata, scale=0.5)\n",
    "    out = v.draw_instance_predictions(instances.to(\"cpu\"))\n",
    "    plt.figure()\n",
    "    plt.imshow(out.get_image())\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task (d): Evaluate pre-trained Faster R-CNN, DeTR and YOLOv(>8) on KITTI-MOTS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"kitti_mots\", output_dir=cfg.OUTPUT_DIR)\n",
    "val_loader = build_detection_test_loader(cfg, \"kitti_mots\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
    "# another equivalent way to evaluate the model is to use `trainer.test`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task (e): Fine-tune Faster R-CNN, DeTR and YOLO on KITTI-MOTS (Similar Domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instances_ids = [19, 20, 9, 7, 1, 8, 15, 11, 13, 18, 4, 5]\n",
    "test_instances_ids = [10, 6, 2, 16, 0, 17, 3, 14, 12]\n",
    "\n",
    "for split in [\"train\", \"test\"]:\n",
    "    instances_ids = train_instances_ids if split == \"train\" else test_instances_ids\n",
    "    DatasetCatalog.register(f\"kitti_mots_{split}\", lambda: build_kitti_mots_dicts(\"/home/mcv/datasets/C5/KITTI-MOTS\", instances_ids=instances_ids))\n",
    "    MetadataCatalog.get(f\"kitti_mots_{split}\").set(thing_classes=[\"person\", \"bicycle\", \"car\"])\n",
    "kitti_mots_metadata = MetadataCatalog.get(\"kitti_mots_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
    "# Update datasets\n",
    "cfg.DATASETS.TRAIN = (\"kitti_mots_train\", )\n",
    "cfg.DATASETS.TEST = (\"kitti_mots_test\", )\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 2    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 8   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# Output folder\n",
    "cfg.OUTPUT_DIR = \"/ghome/c5mcv07/C5_G7_MCV/Week_1/faster-rcnn/output/pre_trained_inference\"\n",
    "cfg.MODEL.DEVICE = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate finetune\n",
    "\n",
    "cfg = get_cfg()\n",
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = \"/ghome/c5mcv07/C5_G7_MCV/Week_1/faster-rcnn/output/pre_trained_inference/model_final.pth\"  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.0   # set a custom testing threshold\n",
    "# Output folder\n",
    "cfg.OUTPUT_DIR = \"/ghome/c5mcv07/C5_G7_MCV/Week_1/faster-rcnn/output/pre_trained_inference\"\n",
    "cfg.MODEL.DEVICE = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dicts_test = build_kitti_mots_dicts(\"/home/mcv/datasets/C5/KITTI-MOTS\", instances_ids=train_instances_ids)\n",
    "random.seed(42)\n",
    "for d in random.sample(dataset_dicts_test, 1):\n",
    "    img = cv2.imread(d[\"file_name\"])[:, :, ::-1]\n",
    "    visualizer = Visualizer(img, metadata=kitti_mots_metadata, scale=0.5)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    plt.figure()\n",
    "    plt.imshow(out.get_image())\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference\n",
    "random.seed(42)\n",
    "predictor = CustomPredictor(cfg)\n",
    "for d in random.sample(dataset_dicts_test, 1):\n",
    "    file_name = d[\"file_name\"]\n",
    "    image_id = d[\"image_id\"]\n",
    "    img = cv2.imread(file_name)[:, :, ::-1]\n",
    "    outputs = predictor(img)  # Run inference\n",
    "    instances = outputs[\"instances\"]\n",
    "    \n",
    "    # We can use `Visualizer` to draw the predictions on the image.\n",
    "    v = Visualizer(img, kitti_mots_metadata, scale=0.5)\n",
    "    out = v.draw_instance_predictions(instances.to(\"cpu\"))\n",
    "    plt.figure()\n",
    "    plt.imshow(out.get_image())\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = COCOEvaluator(\"kitti_mots_test\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"kitti_mots_test\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
